<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2023-06-21T12:25:48-05:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">AirLab</title><subtitle>Researching, developing, and testing autonomous robots at Carnegie Mellon University
</subtitle><entry><title type="html">Real-time Fault Detection for Autonomous Aerial Vehicles</title><link href="http://0.0.0.0:4000/fault-detection/" rel="alternate" type="text/html" title="Real-time Fault Detection for Autonomous Aerial Vehicles" /><published>2020-07-15T05:50:07-05:00</published><updated>2020-07-15T05:50:07-05:00</updated><id>http://0.0.0.0:4000/fault-detection</id><content type="html" xml:base="http://0.0.0.0:4000/fault-detection/">The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation.

In this project, we developed a real-time approach to detecting anomalies in the behavior of an aircraft. Additionally, we created and published a dataset of the 47 flight sequences where the anomalies happen. Our anomaly detection method is based on the Recursive Least Squares. The approach models the relationship between correlated input-output pairs online and uses the model to detect the anomalies. The result is an easy-to-deploy anomaly detection method that does not assume a specific aircraft model and can detect many types of faults and anomalies in a wide range of autonomous aircraft. The experiments on this method show a precision of 88.23%, recall of 88.23% and 86.36% accuracy for over 22 flight tests. For more details about the work, please refer to the publications below.

More information about the dataset is available [here](../alfa-dataset).

{% youtube HCtGbnqjKj8 %}

### Source Code

An early version of the source code for the method written in C++ (with ROS Kinetic) can be accessed from [here](https://bitbucket.org/castacks/online_system_identification/). The code can be used with the `rosbag` files in the ALFA dataset without any modification.

### Publications

The real-time anomaly detection method for the autonomous aerial vehicles is described in the following publication (access on [arXiv](https://arxiv.org/abs/1907.00511) or [IEEE Xplore](https://ieeexplore.ieee.org/document/8794286)):

*BibTeX:*

@inproceedings{keipour:detection:2019,
author={Azarakhsh Keipour and Mohammadreza Mousaei and Sebastian Scherer},
booktitle={2019 IEEE International Conference on Robotics and Automation (ICRA)},
title={Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles},
year={2019},
month={May},
pages={5679-5685},
doi={10.1109/ICRA.2019.8794286}
}

*IEEE Style:*

A. Keipour, M. Mousaei, and S. Scherer, “Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles,” in 2019 IEEE International Conference on Robotics and Automation (ICRA), May 2019, pp.5679-5685. doi: 10.1109/ICRA.2019.8794286.

The dataset is described [here](../alfa-dataset) and in the following publication (access on [arXiv](https://arxiv.org/abs/1907.06268) or [The International Journal of Robotics Research website](https://doi.org/10.1177/0278364920966642)):

*BibTeX:*

@article{keipour:dataset:2019,
author={Azarakhsh Keipour and Mohammadreza Mousaei and Sebastian Scherer},
title={ALFA: A Dataset for UAV Fault and Anomaly Detection},
journal = {The International Journal of Robotics Research},
volume = {0},
number = {0},
pages = {1-6},
month = {October},
year = {2020},
doi = {10.1177/0278364920966642},
URL = {&lt;https://doi.org/10.1177/0278364920966642}&gt;,
eprint = {&lt;https://doi.org/10.1177/0278364920966642}&gt;
}

*IEEE Style:*

A. Keipour, M. Mousaei, and S. Scherer, “ALFA: A dataset for UAV fault and anomaly detection,” The International Journal of Robotics Research, vol. 0. no.  0,  pp.  1–6,  October  2020.  [Online]. Available:&lt;https://doi.org/10.1177/0278364920966642&gt;

### Contact

Azarakhsh Keipour - (keipour [at] cmu [dot] edu)

Mohammadreza Mousaei - (mmousaei [at] cmu [dot] edu)

Sebastian Scherer - (basti [at] cmu [dot] edu)

### Acknowledgments

This work was supported through NASA Grant Number NNX17CL06C.</content><author><name>Azarakhsh Keipour</name></author><category term="research" /><summary type="html">The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/img/posts/2019-08-01-fault-detection/AnomalyDetection2018.jpg" /><media:content medium="image" url="http://0.0.0.0:4000/img/posts/2019-08-01-fault-detection/AnomalyDetection2018.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Autonomous UAV-based Multi-Model High-Resolution Reconstruction for Aging Bridge Inspection</title><link href="http://0.0.0.0:4000/research/2020/01/31/shimizu/" rel="alternate" type="text/html" title="Autonomous UAV-based Multi-Model High-Resolution Reconstruction for Aging Bridge Inspection" /><published>2020-01-31T04:50:07-06:00</published><updated>2020-01-31T04:50:07-06:00</updated><id>http://0.0.0.0:4000/research/2020/01/31/shimizu</id><content type="html" xml:base="http://0.0.0.0:4000/research/2020/01/31/shimizu/">The conventional way of aging infrastructure (e.g. bridges and tunnels) inspection can be time-consuming and dangerous for humans. Therefore we are developing technologies to let UAVs help collect, process and analyze data automatically.  

![drone](/img/posts/2020-01-31-shimizu/drone.png)
*A customized DJI M210 drone carrying the designed payload, which contains stereo pair, rotating LiDAR, IMU and thermal camera.*
&lt;!-- &lt;img src=&quot;/img/posts/2020-01-31-shimizu/drone.png&quot; alt=&quot;drone&quot; class=&quot;center&quot; width=&quot;500&quot;/&gt; --&gt;

To achieve autonomy, we build UAVs with customized sensing payload (cameras, LiDAR, IMU, thermal sensors, etc.). Visual and LiDAR-based SLAM methods are applied to achieve real-time robust state estimation. Coverage planning algorithms ensure visual coverage of the surface being inspected.

**LiDAR-enhanced Structure-from-Motion**: We augmented the traditional Structure-from-Motion pipeline with LiDAR information. Observations from both sensors are fused into a single cost function and optimize for all parameters simultaneously. Take a look at the reconstructed model of the Pearl Harbor Memorial Bridge Tunnel in Connecticut ([link](https://perceptron.ri.cmu.edu/project/shimizu/ct_bridge_new/merged/merged.html)).

**DL aided Stereo**: To improve the robustness of stereo matching algorithms in low textured circumstances, we trained a deep neural network to predict the disparity uncertainity, which provide a guide for correspondance searching.  

**2D-3D Localization**: We proposed a global 2D-3D registration method to estimate 2D-3D line correspondences and the camera pose in untextured point clouds of structured environments.

On the inspection and analysis side, we are collaborating with Professor [Kenji Shimada](http://www.andrew.cmu.edu/user/shimada/) and [Kris Kitani](http://www.cs.cmu.edu/~kkitani/) for FEA and image-based crack detection.

This project is sponsored by [Shimizu Institute of Technology](https://www.shimz.co.jp/en/company/about/sit/) in Tokyo, Japan.

&lt;!-- ## Videos
{% youtube dJaaF8POB64 %}
{% youtube GUcKZ2PLPRQ %}
{% youtube 7vx0hXDLCWY %}
{% youtube XpGvhL5QHtQ %} --&gt;

## Publications

Zhen, W., Hu, Y., Liu, J. and Scherer, S.. **A joint optimization approach of lidar-camera fusion for accurate dense 3-d reconstructions**. IEEE Robotics and Automation Letters, 4(4), pp.3585-3592. [[PDF]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8760386) [[Video]](https://www.youtube.com/watch?v=dJaaF8POB64)

Zhen, W., Hu, Y., Yu, H. and Scherer, S.. **LiDAR Enhanced Structure-from-Motion**. To appear in 2020 International Conference on Robotics and Automation (ICRA). IEEE. [[PDF]](https://arxiv.org/pdf/1911.03369.pdf) [[Video]](https://www.youtube.com/watch?v=GUcKZ2PLPRQ)

Yu, H., Zhen, W., Yang, W. and Scherer, S.. **Line-based Camera Pose Estimation in Point Cloud of Structured Environments**. arXiv preprint arXiv:1912.05013. [[PDF]](https://arxiv.org/pdf/1912.05013.pdf) [[Video]](https://youtu.be/7vx0hXDLCWY)

Hu, Y., Zhen, W. and Scherer, S.. **Deep-Learning Assisted High-Resolution Binocular Stereo Depth Reconstruction**. To appear in 2020 International Conference on Robotics and Automation (ICRA). IEEE. [[PDF]](https://arxiv.org/pdf/1912.05012.pdf) [[Video]](https://www.youtube.com/watch?v=XpGvhL5QHtQ)

&lt;!-- ### Project Crews
[Weikun Zhen](http://theairlab.org/team/weikun/), 
[Yaoyu Hu](http://theairlab.org/team/yaoyuh/), 
[Huai Yu](http://theairlab.org/team/huai/), 
Jingfeng Liu, 
Jumbin Yuan --&gt;

&lt;!-- ## Sponsorship
[&lt;img width=&quot;200&quot; src=&quot;https://www.shimz.co.jp/en/shared/images/shoulder_logo_en.svg&quot;&gt;](https://www.shimz.co.jp/en/company/about/sit/) --&gt;</content><author><name>Weikun Zhen</name></author><category term="research" /><summary type="html">The conventional way of aging infrastructure (e.g. bridges and tunnels) inspection can be time-consuming and dangerous for humans. Therefore we are developing technologies to let UAVs help collect, process and analyze data automatically.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/img/posts/2020-01-31-shimizu/models.jpg" /><media:content medium="image" url="http://0.0.0.0:4000/img/posts/2020-01-31-shimizu/models.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Mapping and SLAM Datasets</title><link href="http://0.0.0.0:4000/slam_datasets/" rel="alternate" type="text/html" title="Mapping and SLAM Datasets" /><published>2018-05-05T05:50:07-05:00</published><updated>2018-05-05T05:50:07-05:00</updated><id>http://0.0.0.0:4000/slam-datasets</id><content type="html" xml:base="http://0.0.0.0:4000/slam_datasets/">Some mapping and SLAM related datasets from some of our previous publications.

## Real-time 3D Scene Layout from a Single Image Using Convolutional Neural Networks

**Publications:** 
* Yang, S., Maturana, D. and Scherer, S., Real-time 3D Scene Layout from a Single Image Using Convolutional Neural Networks., International Conference on Robotics and automation (ICRA), 2016 

**Dataset:** We assemble an image dataset (967 images) for corridor environments. All the images are annotated as ground or wall using polygons. More details and downloads could be found [here](https://drive.google.com/file/d/16yHVv2HIV2pqJj-Z1k8gRSb31enJeMdm/view?usp=sharing).

## CubeSLAM

**Publications:** 
* Yang, S. and Scherer, S, CubeSLAM: Monocular 3D Object SLAM., IEEE Transactions on Robotics, 2019 [PDF](https://arxiv.org/abs/1806.00557)

**Dataset:** Code and dataset [here](https://github.com/shichaoy/cube_slam).

## Semantic 3D Mapping

**Publications:** 
* Yang, S., Huang, Y., and Sebastion, S,  Semantic 3D Occupancy Mapping through Efficient High Order CRFs, IROS 2017 [PDF](https://arxiv.org/pdf/1707.07388.pdf)

**Dataset:** Code and dataset [here](https://github.com/shichaoy/semantic_3d_mapping).

## Pop Up Slam

**Publications:**
* Pop-up SLAM: Semantic Monocular Plane SLAM for Low-texture Environments, IROS 2016, S. Yang, Y. Song, M. Kaess, S. Scherer [PDF](https://shichaoy.github.io/Publications/iros_2016_popslam.pdf)
* Real-time 3D Scene Layout from a Single Image Using Convolutional Neural Networks, ICRA 2016, S. Yang, D. Maturana, S. Scherer [PDF](https://shichaoy.github.io/Publications/icra_2016_sinpop.pdf)


**Dataset:** Code and dataset [here](https://github.com/shichaoy/pop_up_slam).





### Contact

Shichao Yang {shichaoy@andrew.cmu.edu}</content><author><name>Shichao Yang</name></author><category term="datasets" /><summary type="html">Some mapping and SLAM related datasets from some of our previous publications.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/img/posts/2018-05-05-slam-datasets/slamDataset.png" /><media:content medium="image" url="http://0.0.0.0:4000/img/posts/2018-05-05-slam-datasets/slamDataset.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">AirLab showcases research at the White House Frontiers Conference</title><link href="http://0.0.0.0:4000/obama/" rel="alternate" type="text/html" title="AirLab showcases research at the White House Frontiers Conference" /><published>2016-10-13T05:50:07-05:00</published><updated>2016-10-13T05:50:07-05:00</updated><id>http://0.0.0.0:4000/obama</id><content type="html" xml:base="http://0.0.0.0:4000/obama/">Proud to showcase our latest research to Obama and the White House team at the White House Frontiers Conference.  

&lt;center&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;President Obama interacting with technology &amp;amp; advising for &lt;br&gt;Pushing the bounds wherever possible.&lt;a href=&quot;https://twitter.com/hashtag/Keepitgoing?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#Keepitgoing&lt;/a&gt;&lt;a href=&quot;https://twitter.com/hashtag/WHFrontiers?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#WHFrontiers&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/CMU?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#CMU&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/AIrlab?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#AIrlab&lt;/a&gt; &lt;a href=&quot;https://t.co/mfWEnBrhy0&quot;&gt;pic.twitter.com/mfWEnBrhy0&lt;/a&gt;&lt;/p&gt;&amp;mdash; AirLab (@airlabcmu) &lt;a href=&quot;https://twitter.com/airlabcmu/status/788530039444819968?ref_src=twsrc%5Etfw&quot;&gt;October 18, 2016&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;</content><author><name>Cherie Ho</name></author><category term="highlights" /><summary type="html">Proud to showcase our latest research to Obama and the White House team at the White House Frontiers Conference.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/img/posts/2020-02-21-obama/obama-showcase.gif" /><media:content medium="image" url="http://0.0.0.0:4000/img/posts/2020-02-21-obama/obama-showcase.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Autonomous Drone Safety</title><link href="http://0.0.0.0:4000/other/2016/05/01/autonomous-drone-safety/" rel="alternate" type="text/html" title="Autonomous Drone Safety" /><published>2016-05-01T05:50:07-05:00</published><updated>2016-05-01T05:50:07-05:00</updated><id>http://0.0.0.0:4000/other/2016/05/01/autonomous-drone-safety</id><content type="html" xml:base="http://0.0.0.0:4000/other/2016/05/01/autonomous-drone-safety/">Imagine flying robots traveling vast distances to deliver packages and taking pictures- doing work that is either too expensive, time-consuming, dangerous or even impossible for humans to do. Not so long ago this may have sounded like pure science fiction, but today it is a reality. The commercial, governmental and hobby use of drones has grown exponentially in the last few years as they have become more widely available, less expensive, more versatile, and have seen significant increases in their performance and battery life. As drone technology became more and more affordable and the equipment became more easily available, business quickly discovered that drones offered a low-cost, effective alternative to commercial aviation providers. 

The use of drones was quickly adopted by the film and television industry, with sports broadcasting and law enforcement soon realizing the value and implementing the use of drones in their operations. Scientists have adopted the use of drones to monitor wildlife and to collect data in dangerous situations they have not had access to before such as inside a live volcano. As a basic concept, the idea of an Unmanned Aerial Vehicle (UAV or “drone”) is “childishly” simple: a miniature plane that can be piloted remotely. The major difference between UAVs and the toys of our childhood is the sophistication of the vehicles themselves and of their navigation and pilot systems. Given that these vehicles enter civil airspace and will continue to do so more and more as they begin to be used for an increasing number of civilian activities, the safety and security of UAV software has become critical. It’s paramount that we raise the stakes in terms of the inherent safety of these systems to avoid collisions, and formal guarantees on the &lt;span class=&quot;skimlinks-unlinked&quot;&gt;safety.This&lt;/span&gt; expansion in UAV’s challenges the FAA’s goal “to provide the safest, most efficient aerospace system in the world.” With no human pilot onboard, the control software is chiefly responsible for maintaining UAV safety and security. As demanded by FAA airworthiness rules and the military, as well as for operations close to humans, it is generally necessary to make strong assertions about the safety of a system. This expansion in UAV’s challenges the FAA’s goal “to provide the safest, most efficient aerospace system in the world.” With no human pilot onboard, the control software is chiefly responsible for maintaining UAV safety and security. As demanded by FAA airworthiness rules and the military, as well as for operations close to humans, it is generally necessary to make strong assertions about the safety of a &lt;span class=&quot;skimlinks-unlinked&quot;&gt;system.The&lt;/span&gt;FAA’s policy statement focused on safety concerns posed by the widespread use of UAVs, which the FAA noted “range in size from wingspans of six inches to 246 feet; and can weigh from approximately four ounces to over 25,600 pounds.” The rapid proliferation of UAV’s also worried the FAA, which noted that in 2007, at least 50 companies, universities, and government organizations were developing and producing some 155 unmanned aircraft designs. “The concern was not only that unmanned aircraft operations might interfere with commercial and general aviation aircraft operations,” wrote the FAA, “but that they could also pose a safety problem for other airborne vehicles, and persons or property on the ground.” The major primary safety concerns arising from the use of UAVs in the United States are:  Inability for UAVs to recognize and avoid other aircraft and airborne objects in a manner similar to manned aircraft;  Vulnerabilities in the command and control of UAV operations. In other words, GPS-jamming, hacking and the potential for cyber-terrorism;  Difficulties in guaranteeing the safety of the system  Complexity of autonomy algorithms and challenges in designing an autonomy architecture for certification. One of the primary consequences of the separation between aircraft and operator is that the operator is deprived of a range of sensory cues that are available to the pilot of a manned aircraft. Therefore, a robot must be able to reliably detect and recognize obstacles before it can avoid them. Rather than receiving direct sensory input from the environment in which his/her vehicle is operating, a UAV operator receives only that sensory information provided by onboard sensors via datalink. Currently, this consists primarily of visual imagery covering a restricted field-of-view. Sensory cues that are lost therefore include ambient visual information, kinesthetic/vestibular input, and sound. As compared to the pilot of a manned aircraft, thus, a UAV operator can be said perform in relative “sensory isolation” from the vehicle under his/her control. Some of the environmental challenges faced by the Drones are from different weather conditions like fog, wind while it can also face a lot of small obstacles on its way. Flying in wind can be difficult and in particular challenges the control and autonomy algorithms to guarantee that correct execution is possible. Collision avoidance is an important requirement for autonomous flights. Although multiple solutions for obstacle detection and collision avoidance of UAV’s exist, these solutions suffer from different drawbacks. In general, the existing solutions can be divided into two types: The first type contains simple collision avoidance solutions which are based on avoiding collisions by steering the vehicle into opposite direction using different techniques. The biggest drawback of such solutions is that it is challenging to guarantee that these steering/reactive methods will reach a goal and that the combined avoidance behavior will avoid all obstacles under all situations. The second type can be described as a search or optimization algorithm based solution. These solutions avoid collisions by mapping, positioning, and planning within a map. Planning enables the drones to deliberately avoid collisions. Compared to the first type, these solutions do not limit the mission, but the collision avoidance requires a more precise understanding of the world and potentially requires considerable memory and computational power compared to the already mentioned simple solutions. Software developed for use in larger drones falls under the guidelines of DO-178, “Software Considerations in Airborne Systems and Equipment Certification.” Both DO-178B and the recently ratifiedSoftware developed for use in larger drones falls under the guidelines of DO-178, “Software Considerations in Airborne Systems and Equipment Certification.” Both DO-178B and the recently ratified DO-178C provide detailed guidelines for the production of all software for airborne systems and equipment, whether safety-critical or not. As part of these guidelines, DO-178B/C defines Design Assurance Levels (DALs) with Level A involving the most rigorous safeguard against failure. Software developed for use in larger drones falls under the guidelines of DO-178, “Software Considerations in Airborne Systems and Equipment Certification.” Both DO-178B and the recently ratified DO-178C provide detailed guidelines for the production of all software for airborne systems and equipment, whether safety-critical or not. As part of these guidelines, DO-178B/C defines Design Assurance Levels (DALs) with Level A involving the most rigorous safeguard against failure. One of the challenges in guaranteeing that autonomous drone software is safe is that the number of test cases required for autonomy algorithms makes their exhaustive generation or testing infeasible with simple methods. The “smartness” of the drone is essentially the number of different behavior the drone can choose from. These choices make verification challenging. Another challenge in DO-178 verification is that the typical fallback for a failure in avionics systems is to hand back control to the pilot. However, for an autonomous drone flying out of line-of-sight this is not an option anymore. One of the focus areas of the AirLab at Carnegie Mellon is to develop safe drones and technologies. Over the years, we have developed many collision avoidance algorithms to avoid collision with the terrain from small quadrotors[4] to medium sized helicopters[5], and full-scale autonomous helicopters[6]. More recently, our group has also started to focus on giving stronger guarantees for the safety of an autonomous system. In particular, we have looked at if we can show the safety trajectories being disturbed by wind[7], guaranteeing avoidance of late detected wires[8], and showing the correctness of motion algorithms . &lt;strong&gt;Authors &lt;/strong&gt; Sebastian Scherer Sahil Nyati &lt;strong&gt;References&lt;/strong&gt; 1) Calhoun, G.L., Draper, M.H., Ruff, H.A., &amp;amp; Fontejon, J.V. (2002). Utility of a tactile display for cueing faults. Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting,2144-2148. 2) Van Erp, J.B.F., &amp;amp; Van Breda, L. (1999). Human factors issues and advanced interface design in maritime unmanned aerial vehicles: A project overview (Report TNO TM-99-A004). Soesterberg, The Netherlands: TNO Human Factors Research Institute. 3) Pitchford, Mark. “What’s Needed to Ensure Safety and Security in UAV Software.” Military EmbeddedSystems. 4) Stephen T. Nuske, Sanjiban Choudhury, Sezal Jain, Andrew D. Chambers, Luke Yoder, Sebastian Scherer, Lyle J. Chamberlain,Hugh Cover, and Sanjiv Singh, “Autonomous Exploration and Motion Planning for an Unmanned Aerial Vehicle Navigating Rivers,” Journal of Field Robotics, June, 2015 5) Sebastian Scherer, Sanjiv Singh, Lyle J. Chamberlain, and Mike Elgersma, “Flying Fast and Low Among Obstacles: Methodology and Experiments,” The International Journal of Robotics Research, Vol. 27, No. 5, pp. 549-574, May, 2008 6) Sankalp Arora, Sanjiban Choudhury, Sebastian Scherer, and Daniel Althoff, “A Principled Approach to Enable Safe and High-Performance Maneuvers for Autonomous Rotorcraft,” AHS 70th Annual Forum, Montre ́al, Que ́bec, Canada, May 20–22, May, 2014 7) Daniel Althoff and Sebastian Scherer, “Connected Invariant Sets for High-Speed Motion Planning in Partially-Known Environments,” 2015 IEEE International Conference on Robotics and Automation, March, 2015 8) Daniel Althoff, Matthias Althoff, and Sebastian Scherer, “Online Safety Verification of Trajectories for Unmanned Flight with Offline Computed Robust Invariant Sets,” IEEE/RSJ International Conference on Intelligent Robots and Systems, September, 2015</content><author><name>AirLab</name></author><category term="other" /><summary type="html">Imagine flying robots traveling vast distances to deliver packages and taking pictures- doing work that is either too expensive, time-consuming, dangerous or even impossible for humans to do. Not so long ago this may have sounded like pure science fiction, but today it is a reality. The commercial, governmental and hobby use of drones has grown exponentially in the last few years as they have become more widely available, less expensive, more versatile, and have seen significant increases in their performance and battery life. As drone technology became more and more affordable and the equipment became more easily available, business quickly discovered that drones offered a low-cost, effective alternative to commercial aviation providers.</summary></entry></feed>
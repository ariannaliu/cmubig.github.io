


<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>TartanVO: A Generalizable Learning-based VO - AirLab</title>
    
    <link rel="stylesheet" href="/assets/css/app.css">

    <link rel="shortcut icon" type="image/ico" href="/img/favicon/favicon.ico" />

    <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
    <link rel="manifest" href="/img/favicon/site.webmanifest">
    <link rel="mask-icon" href="/img/favicon/safari-pinned-tab.svg" color="#cc002b">
    <meta name="msapplication-TileColor" content="#b91d47">
    <meta name="theme-color" content="#ffffff">

    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  
  
    <script>
      $(document).ready(function () {
          $('.content a').attr({'target':'_blank', 'rel':'noopener noreferrer'});
        });
    </script>
  

    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>TartanVO: A Generalizable Learning-based VO | AirLab</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="TartanVO: A Generalizable Learning-based VO" />
<meta name="author" content="Wenshan Wang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="TartanVO" />
<meta property="og:description" content="TartanVO" />
<link rel="canonical" href="http://0.0.0.0:4000/tartanvo/" />
<meta property="og:url" content="http://0.0.0.0:4000/tartanvo/" />
<meta property="og:site_name" content="AirLab" />
<meta property="og:image" content="http://0.0.0.0:4000/img/posts/2020-12-13-tartanvo/tartanvo_web_header.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-13T07:13:37-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://0.0.0.0:4000/img/posts/2020-12-13-tartanvo/tartanvo_web_header.gif" />
<meta property="twitter:title" content="TartanVO: A Generalizable Learning-based VO" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Wenshan Wang"},"image":"http://0.0.0.0:4000/img/posts/2020-12-13-tartanvo/tartanvo_web_header.gif","headline":"TartanVO: A Generalizable Learning-based VO","url":"http://0.0.0.0:4000/tartanvo/","datePublished":"2020-12-13T07:13:37-06:00","@type":"BlogPosting","description":"TartanVO","dateModified":"2020-12-13T07:13:37-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/tartanvo/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ERWFHDG4GX"></script>
<script>
  window['ga-disable-G-ERWFHDG4GX'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-ERWFHDG4GX');
</script><!-- head scripts --><!-- Added by Chen -->
    <script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=5ee902d30e78e50012567eb4&product=inline-follow-buttons&cms=sop' async='async'></script>

    <!-- for mathjax support -->
    

</head>


<body>
    
    
<nav class="navbar is-primary" >
    <div class="container">
        <div class="navbar-brand">
            <a href="/" class="navbar-item navbar-logo">
                AirLab
            </a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu">
            <div class="navbar-start">
                <a href="/" class="navbar-item ">Home</a>
                
                
                    
                    <a href="/research/" class="navbar-item ">Research</a>
                    
                
                    
                    <a href="/publications/" class="navbar-item ">Publications</a>
                    
                
                    
                    <a href="/news/" class="navbar-item ">News</a>
                    
                
                    
                    <div class="navbar-item has-dropdown is-hoverable">
                        <a href="/current-members/" class="navbar-link ">Team</a>
                        <div class="navbar-dropdown">
                            
                            <a href="/current-members/" class="navbar-item ">Current Members</a>
                            
                            <a href="/alumni/" class="navbar-item ">Alumni</a>
                            
                        </div>
                    </div>
                    
                
                    
                    <a href="/contact/" class="navbar-item ">Contact</a>
                    
                
                    
                    <a href="/openings/" class="navbar-item ">Openings</a>
                    
                
                
            </div>
        </div>
    </div>
</nav>

    
    
    <section
    class="hero  is-medium  is-bold is-primary"
    >
    <div class="hero-body">
        <div class="container">
            
            <p class="title is-2">TartanVO: A Generalizable Learning-based VO</p>
            <p class="subtitle is-3"></p>
            <p class="subtitle is-3">
                
                
                
            </p>
        </div>
    </div>
</section>

<style>
    .button.is-info {
        background-color: #025EBE;
        border-color: transparent;
        color: #fff;
        padding-left: 10px;
        padding-right: 10px;
        padding-top: 0px;
        height: 50px;
        padding-bottom: 0px;
        font-size: medium;
    }

    .button.is-info.is-hovered {
        background-color: #3298dc;
        border-color: transparent;
        color: #fff;
    }
</style>
    
    


    <section class="section">
        <div class="container">
            <div class="columns">
                

                
                <div class="column is-8">
                      
<div style="text-align: center; display: block; margin-left:auto; margin-right:auto">
    <img style="text" src="/img/posts/2020-12-13-tartanvo/tartanvo_web_header.gif" alt="TartanVO: A Generalizable Learning-based VO" />
</div>


<!-- Figure out the relative link to the author -->








<div class="content">

	<p>
	<div style="font-size: 13px">Published:
		<time datetime="2020-12-13T07:13:37-06:00">Dec 13, 2020</time> by
		<div style="font-weight: bold; color: #3399ff; display: inline">
			
			Wenshan Wang
			
		</div>
	</div>
	</p>

	<h1>TartanVO: A Generalizable Learning-based VO</h1>

	<p>Visual odometry remains a challenging problem in real-world applications. Geometric-based methods are not robust enough to many real-life factors, including illumination change, bad weather, dynamic objects, and aggressive motion. Learning-based methods do not generalize well and have only been trained and tested on the same dataset.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/tartanvo_1.gif" alt="Geometry-based methods" />
</figure>

<p>It is widely accepted that by leveraging a large amount of data, deep-neural-network-based methods can learn a better feature extractor than engineered ones, resulting in a more capable and robust model. But why havenâ€™t we seen the deep learning models outperform geometry-based methods and work on all kind of datasets yet? We argue that there are two main reasons. First, <b> the existing VO models are trained with insufficient diversity</b>, which is critical for learning-based methods to be able to generalize. By diversity, we mean diversity both in the scenes and motion patterns. For example, a VO model trained only on outdoor scenes is unlikely to be able to generalize to an indoor environment. Similarly, a model trained with data collected by a camera fixed on a ground robot, with limited pitch and roll motion, will unlikely be applicable to drones. Second, <b>most of the current learning-based VO models neglect some fundamental nature of the problem which is well formulated in geometry-based VO theories</b>. From the theory of multi-view geometry, we know that recovering the camera pose from a sequence of monocular images has scale ambiguity. Besides, recovering the pose needs to take account of the camera intrinsic parameters. Without explicitly dealing with the scale problem and the camera intrinsics, a model learned from one dataset would likely fail in another dataset, no matter how good the feature extractor is.</p>

<p>To this end, we propose a learning-based method that can solve the above two problems and can generalize across datasets. Our contributions come in three folds.</p>

<p>1). We demonstrate the crucial effects of data diversity on the generalization ability of a VO model by comparing performance on different quantities of training data.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/diverse.png" alt="diversity" />
 <figcaption>
  Generalization ability with respect to different quantities of training data. Blue: training loss, orange: testing loss on three unseen environments. Testing loss drops constantly with increasing quantity of training data.
 </figcaption>
</figure>

<p>2). We design an up-to-scale loss function to deal with the scale ambiguity of monocular VO.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/trans.png" alt="scale" />
 <figcaption>
   Comparison of the loss curve w/ and w/o up-to-scale loss function. a) The training and testing loss w/o the up-to-scale loss. b) The translation and rotation loss of a). Big gap exists between the training and testing translation losses (orange arrow in b)). c) The training and testing losses w/ up-to-scale loss. d) The translation and rotation losses of c). The translation loss gap decreases.
 </figcaption>
</figure>

<p>3). We create an intrinsics layer (IL) in our VO model enabling generalization across different cameras.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/architec2.png" alt="architecture" />
 <figcaption>
  The two-stage network architecture. The model consists of a matching network, which estimates optical flow from two consecutive RGB images, followed by a pose network predicting camera motion from the optical flow. We add a intrinsics layer to explicitly model the camera intrinsics. 
 </figcaption>
</figure>

<p>To our knowledge, our model is the first learning-based VO that has competitive performance in various real-world datasets without finetuning. Furthermore, compared to geometry-based methods, our model is significantly more robust in challenging scenes.</p>

<p>We tested the model on the challenging sequences of TartanAir dataset.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/tartan_SH_trajs.png" alt="tartanair results" />
 <figcaption>
  The black dashed line represents the ground truth. The estimated trajectories by TartanVO and the ORB-SLAM monocular algorithm are shown in orange and blue lines, respectively. The ORB-SLAM algorithm frequently loses tracking in these challenging cases. It fails in 9/16 testing trajectories. Note that we run full-fledge ORB-SLAM with local bundle adjustment, global bundle adjustment, and loop closure components. In contrast, although TartanVO only takes in two images, it is much more robust than ORB-SLAM.
 </figcaption>
</figure>

<p>Our model can be applied to the EuRoC dataset without any finetuning.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/euroc_trajs.png" alt="euroc results" />
 <figcaption>
  The visualization of 6 EuRoC trajectories in Table 3. Black: ground truth trajectory, orange: estimated trajectory
 </figcaption>
</figure>

<p>We also test the TartanVO using data collected by a customized senor setup.</p>

<figure>
 <img src="/img/posts/2020-12-13-tartanvo/realsense3.png" alt="realsense results" />
 <figcaption>
   TartanVO outputs competitive results on D345i IR data compared to T265 (equipped with fish-eye stereo camera and an IMU). a) The hardware setup. b) Trail 1: smooth and slow motion. c) Trail 2: smooth and medium speed. d) Trail 3: aggressive and fast motion. 
 </figcaption>
</figure>

<h3 id="source-code-and-dataset">Source Code and Dataset</h3>

<p>We provide the TartanVO model and a ROS node implementation <a href="https://github.com/castacks/tartanvo">here</a>. We are using the TartanAir dataset, which can be accessed from the AirLab <a href="http://theairlab.org/tartanair-dataset">dataset page</a>.</p>

<h3 id="videos">Videos</h3>

<div class="video-wrapper"><iframe src="http://www.youtube.com/embed/NQ1UEh3thbU" frameborder="0" allowfullscreen=""></iframe></div>

<h3 id="publication">Publication</h3>

<p>This work has been accepted by the Conference on Robot Learning (CoRL) 2020. Please see <a href="https://arxiv.org/pdf/2011.00359.pdf">the paper</a> for more details.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{tartanvo2020corl,
  title =   {TartanVO: A Generalizable Learning-based VO},
  author =  {Wang, Wenshan and Hu, Yaoyu and Scherer, Sebastian},
  booktitle = {Conference on Robot Learning (CoRL)},
  year =    {2020}
}
</code></pre></div></div>

<h3 id="contact">Contact</h3>

<p>Wenshan Wang - (wenshanw [at] andrew [dot] cmu [dot] edu)</p>

<p>Yaoyu Hu - (yaoyuh [at] andrew [dot] cmu [dot] edu)</p>

<p>Sebastian Scherer - (basti [at] cmu [dot] edu)</p>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>This work was supported by ARL award #W911NF1820218. Special thanks to Yuheng Qiu and Huai Yu from Carnegie Mellon University for preparing simulation results and experimental setups.</p>

</div>

<div class="tags">
	
</div>




                </div>
                
                <div class="column is-4-desktop is-12-tablet">
                    <p class="title is-4">Latest Research</p>

<div class="columns is-multiline">
    
    <div class="column is-12">
        <a href="/shimizu/">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2023-01-17-shimizu-updated/thumbnail_sfm.jpg" alt="Autonomous UAV-based Multi-Model High-Resolution Reconstruction for Aging Bridge Inspection (new)" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">Autonomous UAV-based Multi-Model High-Resolution Reconstruction for Aging Bridge Inspection (new)</div>
            
            <p>During a 4-year research collaboration with an international corporation in civil engineering (Sh...</p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Jan 17, 2023</p>
    </footer>
</div>
</a>

    </div>
    
    <div class="column is-12">
        <a href="/wildfire/">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2022-12-08-wildfire/wildfire_display_card.gif" alt="Wildland Fire Safety Monitoring" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">Wildland Fire Safety Monitoring</div>
            
            <p>The dangers of wildfire continues to grow due to climate change. Mere minutes can turn a previous...</p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Dec 25, 2022</p>
    </footer>
</div>
</a>

    </div>
    
    <div class="column is-12">
        <a href="/aitf/">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2022-09-12-aitf/fig1.jpeg" alt="How do you train AI Pilots?" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">How do you train AI Pilots?</div>
            
            <p>We need more pilots. AI can help! Advanced Aerial Mobility (AAM) is an inclusive term that covers...</p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Sep 12, 2022</p>
    </footer>
</div>
</a>

    </div>
    
</div>




                </div>
                
            </div>
        </div>
    </section>
     <style>
  #blocks {
    width: 100%;
    height: 60px;
    margin: 0 auto;
    /* background-color: #ffe; */
  }

  #block1 {
    height: 33.33%;
    width: 30%;
    /* background: red; */
    float: left;
  }

  #block2 {
    height: 33.33%;
    width: 40%;
    /* background: yellow; */
    float: left;
  }

  #block3 {
    height: 33.33%;
    width: 30%;
    /* background: green; */
    float: right;
  }
</style>

<footer class="footer">
  <div class="container">
    <!-- 
        <div class="columns is-multiline">
            
            <div class="column has-text-centered">
                <div>
                    <a href="/" class="link">Home</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/blog/" class="link">Blog</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/products/" class="link">Products</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/privacy-policy/" class="link">Privacy Policy</a>
                </div>
            </div>
            
        </div>
         -->
    <div id="blocks">
      <div id="block1"><img src="/img/logos/large.png" alt="BIG Lab Logo" style="width:30%;"></div>
      <div id="block2">
        <center>

          <!-- <a class="button" itemprop="email" href="https://www.facebook.com" target="_blank">
                <i class="fab fa-github"></i>
              </a> -->
          <!-- <a class="button" itemprop="email" href="https://www.facebook.com" target="_blank">
                <i class="fab fa-facebook"</i>
              </a> -->
          <a class="button" itemprop="facebook" href="https://www.facebook.com/airlabcmu/" target="_blank">
            <i class="fab fa-facebook fa-lg" style="height:100%;"></i>
          </a>
          <a class="button" itemprop="twitter" href="https://www.twitter.com/airlabcmu/" target="_blank">
            <i class="fab fa-twitter fa-lg"></i>
          </a>
          <a class="button" itemprop="medium" href="https://medium.com/airlabcmu" target="_blank">
            <i class="fab fa-medium fa-lg"></i>
          </a>
          <a class="button" itemprop="github" href="https://github.com/castacks" target="_blank">
            <i class="fab fa-github fa-lg"></i>
          </a>
          <a class="button" itemprop="bitbucket" href="https://bitbucket.org/castacks/" target="_blank">
            <i class="fab fa-bitbucket fa-lg"></i>
          </a>
          <br>
          <br>
          <p class="">&copy; 2021 | Built using the <a href="https://github.com/chrisrhymes/bulma-clean-theme">Bulma
              Clean Theme</a></p>
        </center>
      </div>
      <div id="block3"><img src="/img/riLogo2019.svg" alt="RI Logo" style="float: right;"></div>
    </div>
    <!-- <div>
          <a href="" class="button is-large"><div class="icon"><i class="fab fa-facebook"</i></div></a>
        </div> -->
    <!-- <div class="content is-small has-text-centered">
            <p class="">Â© 2020</p>
        </div> -->
  </div>


</footer> 
    <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts --></body>

</html>